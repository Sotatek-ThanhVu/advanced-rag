{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98dc17cc-06f9-49b9-b753-35f9df147192",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f50a200-3189-458f-a5b2-dfb6ea04b0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7abee21-e426-49b5-a2f9-e8ef06fc06af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "connection_string = os.getenv('CONNECTION_STRING')\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "gemini_api_key = os.getenv('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9736dc9e-d8b5-4b7e-961c-e47ac50c760b",
   "metadata": {},
   "source": [
    "# Define global context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ad5c4c7-1e91-4868-98e5-154db772e60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import ServiceContext, set_global_service_context\n",
    "from llama_index.callbacks import CallbackManager, LlamaDebugHandler\n",
    "from llama_index.embeddings import GeminiEmbedding\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model='gpt-3.5-turbo-1106', temperature=0.0, api_key=openai_api_key)\n",
    "embed_model = GeminiEmbedding(api_key=gemini_api_key)\n",
    "callback_manager = CallbackManager([LlamaDebugHandler(print_trace_on_end=True)])\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm, embed_model=embed_model, callback_manager=callback_manager\n",
    ")\n",
    "\n",
    "set_global_service_context(service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6b403d-edbb-4252-abd6-9f605cf3be95",
   "metadata": {},
   "source": [
    "# Connect to storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "473f180c-7256-4ac9-a481-60fc495d9ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import make_url\n",
    "from llama_index.vector_stores.postgres import PGVectorStore\n",
    "\n",
    "uri = make_url(connection_string)\n",
    "vector_store = PGVectorStore.from_params(\n",
    "    host=uri.host,\n",
    "    port=str(uri.port),\n",
    "    database=uri.database,\n",
    "    user=uri.username,\n",
    "    password=uri.password,\n",
    "    embed_dim=768, # REMEMBER TO CHANGE THIS TO 1536 if using OpenAI Embedding Model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9d8743-8dd6-45e4-ac13-c2ce9a090233",
   "metadata": {},
   "source": [
    "# Create retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5fdc373-6cd2-4d0a-b644-8557781b7a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6304c4c-7eb9-4955-9b18-3d937b5e15fb",
   "metadata": {},
   "source": [
    "## Base retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b8ae51d-2ac2-4118-8f81-eac7d074d73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index.as_retriever(\n",
    "    similarity_top_k=1,\n",
    "    vector_store_kwargs={\n",
    "        'ivfflat_probes': 10,  # higher is better for recall, lower is better for speed. Default = 1\n",
    "        'hnsw_ef_search': 300, # Specify the size of the dynamic candidate list for search. Default = 40\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17056ef4-409b-406b-98eb-745d79412e3b",
   "metadata": {},
   "source": [
    "## Recursive retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa82528c-171c-4ea4-b8d8-79fbe8b2c5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.retrievers import RecursiveRetriever\n",
    "\n",
    "recursive_retriever = RecursiveRetriever(\n",
    "    'vector', retriever_dict={'vector': retriever}, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbca994-869f-43a6-a6ee-77f545949236",
   "metadata": {},
   "source": [
    "\n",
    "# Fusion Retriver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae98413-f5a0-4592-be8a-16269067b058",
   "metadata": {},
   "source": [
    "## Generate new queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85541cf8-5c80-4bd8-a2cd-1d0c7c8bbbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from llama_index import PromptTemplate\n",
    "from llama_index.llms import LLM\n",
    "\n",
    "query_gen_prompt_template = \"\"\"\n",
    "You are a helpful assistant that generates multiple search queries based on a single input query.\n",
    "Generate {num_queries} search queries, one on each line related to the following input query:\n",
    "Query: {query}\n",
    "Queries:\n",
    "\"\"\"\n",
    "\n",
    "# Should I using RAG to generate new queries based on those information?\n",
    "# To avoid ambiguous queries?\n",
    "\n",
    "def generate_queries(llm: LLM, query: str, num_queries: int = 4) -> List[str]:\n",
    "    query_gen_prompt = PromptTemplate(query_gen_prompt_template)\n",
    "    prompt = query_gen_prompt.format(num_queries=num_queries, query=query)\n",
    "    response = llm.complete(prompt)\n",
    "    queries = response.text.split('\\n')\n",
    "\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2dbc852-41d6-4f30-a5eb-505d98ca493c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. \"Upcoming Hawaii conferences 2022\"',\n",
       " '2. \"Best Hawaii conference venues\"',\n",
       " '3. \"Hawaii conference schedule and events\"',\n",
       " '4. \"How to attend Hawaii conferences\"']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_queries(llm, \"Hawaii conferences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da09c18-76e4-427a-b29c-9dcb80079b2b",
   "metadata": {},
   "source": [
    "## Run queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0eb4c56-d0eb-44ed-9b7e-7085745336d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "def run_queries(queries: List[str]):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bb0606-8d88-4b32-93ab-a6eda616b764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from llama_index.retrievers import BaseRetriever\n",
    "\n",
    "class FusionRetriever(BaseRetriever):\n",
    "    def __init__(\n",
    "        self,\n",
    "        retrievers: List[BaseRetriever]\n",
    "    ):\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
