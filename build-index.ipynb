{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f011be45-070c-4509-8267-4a7098ab6c14",
   "metadata": {},
   "source": [
    "# Load local environments from `.env` and define some global variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a3873d-9da3-4614-83e3-d218653e65af",
   "metadata": {},
   "source": [
    "## Load local environments from `.env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99d2ee18-dd63-46e0-90df-009c06a9fee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a34c745f-a211-48f8-b78f-625aaf21d05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "connection_string = os.getenv('CONNECTION_STRING')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954ab56f-57de-4e6a-9d3b-7a18c662eea5",
   "metadata": {},
   "source": [
    "## Define global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fab4a217-29ea-47fd-8a7e-89c04e205f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings import GeminiEmbedding\n",
    "from llama_index.callbacks import CallbackManager, LlamaDebugHandler\n",
    "\n",
    "embed_model = GeminiEmbedding()\n",
    "callback_manager = CallbackManager([\n",
    "    LlamaDebugHandler(print_trace_on_end=True),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f5bb1f-a6a8-4086-9fa4-1454cdce7f2b",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d15a88-4152-413e-93b3-bc453800f6ab",
   "metadata": {},
   "source": [
    "## Load source documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aba13bb9-4dd5-4728-9dec-c958204aaede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from llama_index import Document, SimpleDirectoryReader\n",
    "\n",
    "def load_documents() -> List[Document]:\n",
    "    loader = SimpleDirectoryReader(\n",
    "        input_files=['./documents/_event__202401120928.json']\n",
    "    )\n",
    "    documents = loader.load_data(show_progress=True)\n",
    "    documents = Document(text='\\n\\n'.join([doc.get_content() for doc in documents]))\n",
    "\n",
    "    return [documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "204813a4-ea14-416f-b14a-c2003fb2bed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|███████████████████████████████████████████████| 1/1 [00:00<00:00, 166.66file/s]\n"
     ]
    }
   ],
   "source": [
    "documents = load_documents()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d372f008-8035-403a-a7fb-80085a76cca1",
   "metadata": {},
   "source": [
    "## Parsing source documents into smaller chunks (nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0794162a-00ee-4dff-a92c-f4e7b80e051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from llama_index.node_parser import JSONNodeParser\n",
    "from llama_index.schema import BaseNode\n",
    "\n",
    "def build_nodes(documents: List[Document]) -> List[BaseNode]:\n",
    "    node_parser = JSONNodeParser.from_defaults(callback_manager=callback_manager)\n",
    "    nodes = node_parser.get_nodes_from_documents(\n",
    "        documents=documents, show_progress=True\n",
    "    )\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7990ebb-051d-4000-b700-99c14f899ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d909238f3a74decbdae8ba825cba050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodes = build_nodes(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480e22b7-5f37-4ec2-8575-956307e0f1fe",
   "metadata": {},
   "source": [
    "## Construct ServiceContext and StorageContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b701c4d4-b6f6-4f91-8d37-5b09f563102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from llama_index import ServiceContext, StorageContext\n",
    "from llama_index.callbacks import CallbackManager\n",
    "from llama_index.embeddings import BaseEmbedding\n",
    "from llama_index.vector_stores.postgres import PGVectorStore\n",
    "from sqlalchemy import make_url\n",
    "\n",
    "def build_context(\n",
    "    embed_model: BaseEmbedding | None,\n",
    "    callback_manager: CallbackManager | None,\n",
    ") -> Tuple[ServiceContext, StorageContext]:\n",
    "    service_context = ServiceContext.from_defaults(\n",
    "        embed_model=embed_model, callback_manager=callback_manager\n",
    "    )\n",
    "\n",
    "    uri = make_url(connection_string)\n",
    "    vector_store = PGVectorStore.from_params(\n",
    "        host=uri.host,\n",
    "        port=str(uri.port),\n",
    "        database=uri.database,\n",
    "        user=uri.username,\n",
    "        password=uri.password,\n",
    "        embed_dim=768, # REMEMBER TO CHANGE THIS TO 1536 if using OpenAI Embedding Model\n",
    "    )\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "    return service_context, storage_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c267a26-a379-4cfb-a2bf-35ddcdaa5aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = build_context(embed_model, callback_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb336326-b553-442b-86ac-3f6d5ed3122b",
   "metadata": {},
   "source": [
    "## Construct index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ec1b1bf-589a-40ba-bc96-3f2be8e86e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from llama_index import ServiceContext, StorageContext, VectorStoreIndex\n",
    "from llama_index.schema import BaseNode\n",
    "\n",
    "def build_index(\n",
    "    nodes: List[BaseNode], context: Tuple[ServiceContext, StorageContext]\n",
    ") -> VectorStoreIndex:\n",
    "    index = VectorStoreIndex(\n",
    "        nodes=nodes,\n",
    "        service_context=context[0],\n",
    "        storage_context=context[-1],\n",
    "        show_progress=True,\n",
    "    )\n",
    "\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "179201aa-da11-4320-980a-a039f4ab6554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMEMBER TO CLEAN DATABASE BEFORE RUNNING INDEX CONSTRUCTION\n",
    "# or else the new embedding vector will be appended into old embedding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44997397-48d5-4bd3-8c42-e5cf5a115499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c7a67c9c0d4226ab7469e0e3bf3ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: index_construction\n",
      "    |_embedding ->  6.125391 seconds\n",
      "    |_embedding ->  5.731168 seconds\n",
      "    |_embedding ->  5.832827 seconds\n",
      "    |_embedding ->  5.700512 seconds\n",
      "    |_embedding ->  5.97814 seconds\n",
      "    |_embedding ->  4.164257 seconds\n",
      "    |_embedding ->  2.206623 seconds\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "index = build_index(nodes, context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
